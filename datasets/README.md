## Tasks and datasets used in our experiments


### Chinese word segmentation (CWS):
[**MSR dataset**](http://sighan.cs.uchicago.edu/bakeoff2005/) from SIGHAN2005 Chinese word segmentation Bakeoff.


### Part-of-speech (POS) tagging:
[**CTB5**](https://catalog.ldc.upenn.edu/LDC2005T01) dataset with standard splits.


### Named entity recognition (NER):
[**MSRA dataset**](http://sighan.cs.uchicago.edu/bakeoff2006/) from international Chinese language processing Bakeoff 2006.


### Document classification (DC):
[**THUCNews**](http://thuctc.thunlp.org) dataset from Sina
news with 10 evenly distributed classes.


### Sentiment analysis (SA):
The [**ChnSentiCorp**](https://github.com/pengming617/bert_classification) dataset with 12,000 documents from three domains, i.e., book, computer and hotel.


### Sentence pair matching (SPM):
The [**LCQMC**](http://icrc.hitsz.edu.cn/info/1037/1146.htm) (a large-scale Chinese question matching corpus) dataset, where each
instance in it is a pair of two sentences with a label indicating whether their intent is matched.


### Natural language inference (NLI):
The Chinese part of the [**XNLI**](https://github.com/google-research/bert/blob/master/multilingual.md).